From: Valentine Fatiev <valentinef@nvidia.com>
Subject: [PATCH] BACKPORT: drivers/infiniband/core/umem_dmabuf.c

Change-Id: I28cf6c15f74ea9f208c9641ac9a469538d63df1c
---
 drivers/infiniband/core/umem_dmabuf.c | 16 ++++++++++++++++
 1 file changed, 16 insertions(+)

--- a/drivers/infiniband/core/umem_dmabuf.c
+++ b/drivers/infiniband/core/umem_dmabuf.c
@@ -3,6 +3,7 @@
  * Copyright (c) 2020 Intel Corporation. All rights reserved.
  */
 
+#ifdef HAVE_DMA_BUF_DYNAMIC_ATTACH_GET_4_PARAMS
 #include <linux/dma-buf.h>
 #include <linux/dma-resv.h>
 #include <linux/dma-mapping.h>
@@ -10,7 +11,9 @@
 
 #include "uverbs.h"
 
+#ifdef MODULE_IMPORT_NS
 MODULE_IMPORT_NS(DMA_BUF);
+#endif
 
 int ib_umem_dmabuf_map_pages(struct ib_umem_dmabuf *umem_dmabuf)
 {
@@ -58,8 +61,14 @@ int ib_umem_dmabuf_map_pages(struct ib_u
 		cur += sg_dma_len(sg);
 	}
 
+#ifdef HAVE_SG_APPEND_TABLE
 	umem_dmabuf->umem.sgt_append.sgt.sgl = umem_dmabuf->first_sg;
 	umem_dmabuf->umem.sgt_append.sgt.nents = nmap;
+#else
+	umem_dmabuf->umem.sg_head.sgl = umem_dmabuf->first_sg;
+	umem_dmabuf->umem.sg_head.nents = nmap;
+	umem_dmabuf->umem.nmap = nmap;
+#endif
 	umem_dmabuf->sgt = sgt;
 
 wait_fence:
@@ -68,7 +77,11 @@ wait_fence:
 	 * may be not up-to-date. Wait for the exporter to finish
 	 * the migration.
 	 */
+#ifdef HAVE_DMA_RESV_EXCL_FENCE
 	fence = dma_resv_excl_fence(umem_dmabuf->attach->dmabuf->resv);
+#else
+	fence = dma_resv_get_excl(umem_dmabuf->attach->dmabuf->resv);
+#endif
 	if (fence)
 		return dma_fence_wait(fence, false);
 
@@ -176,7 +189,9 @@ ib_umem_dmabuf_unsupported_move_notify(s
 }
 
 static struct dma_buf_attach_ops ib_umem_dmabuf_attach_pinned_ops = {
+#ifdef HAVE_DMA_BUF_ATTACH_OPS_ALLOW_PEER2PEER
 	.allow_peer2peer = true,
+#endif
 	.move_notify = ib_umem_dmabuf_unsupported_move_notify,
 };
 
@@ -229,3 +244,4 @@ void ib_umem_dmabuf_release(struct ib_um
 	dma_buf_put(dmabuf);
 	kfree(umem_dmabuf);
 }
+#endif
