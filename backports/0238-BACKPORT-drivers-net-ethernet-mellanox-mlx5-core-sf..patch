From: Daniel Jurgens <danielj@mellanox.com>
Subject: [PATCH] BACKPORT: drivers/net/ethernet/mellanox/mlx5/core/sf.c

Change-Id: Ief0ebe67fd6dc3df191b3fd5f783d749de4e18e7
---
 drivers/net/ethernet/mellanox/mlx5/core/sf.c | 68 ++++++++++++++++++++
 1 file changed, 68 insertions(+)

--- a/drivers/net/ethernet/mellanox/mlx5/core/sf.c
+++ b/drivers/net/ethernet/mellanox/mlx5/core/sf.c
@@ -205,7 +205,11 @@ static void free_sf_id(struct mlx5_core_
 
 static void *mlx5_meddev_dma_alloc(struct device *dev, size_t size,
 				   dma_addr_t *dma_handle, gfp_t gfp,
+#ifdef HAVE_STRUCT_DMA_ATTRS
+				   struct dma_attrs *attrs)
+#else
 				   unsigned long attrs)
+#endif
 {
 	return dma_alloc_attrs(dev->parent, size, dma_handle, gfp, attrs);
 }
@@ -213,7 +217,11 @@ static void *mlx5_meddev_dma_alloc(struc
 static void
 mlx5_meddev_dma_free(struct device *dev, size_t size,
 		     void *vaddr, dma_addr_t dma_handle,
+#ifdef HAVE_STRUCT_DMA_ATTRS
+		     struct dma_attrs *attrs)
+#else
 		     unsigned long attrs)
+#endif
 {
 	dma_free_attrs(dev->parent, size, vaddr, dma_handle, attrs);
 }
@@ -221,7 +229,11 @@ mlx5_meddev_dma_free(struct device *dev,
 static int
 mlx5_meddev_dma_mmap(struct device *dev, struct vm_area_struct *vma,
 		     void *cpu_addr, dma_addr_t dma_addr, size_t size,
+#ifdef HAVE_STRUCT_DMA_ATTRS
+		     struct dma_attrs *attrs)
+#else
 		     unsigned long attrs)
+#endif
 {
 	return dma_mmap_attrs(dev->parent, vma, cpu_addr,
 			      dma_addr, size, attrs);
@@ -230,7 +242,11 @@ mlx5_meddev_dma_mmap(struct device *dev,
 static int
 mlx5_meddev_dma_get_sgtable(struct device *dev, struct sg_table *sgt,
 			    void *cpu_addr, dma_addr_t dma_addr, size_t size,
+#ifdef HAVE_STRUCT_DMA_ATTRS
+			    struct dma_attrs *attrs)
+#else
 			    unsigned long attrs)
+#endif
 {
 	return dma_get_sgtable_attrs(dev->parent, sgt, cpu_addr,
 				     dma_addr, size, attrs);
@@ -240,38 +256,67 @@ static dma_addr_t
 mlx5_meddev_dma_map_page(struct device *dev, struct page *page,
 			 unsigned long offset, size_t size,
 			 enum dma_data_direction dir,
+#ifdef HAVE_STRUCT_DMA_ATTRS
+			 struct dma_attrs *attrs)
+#else
 			 unsigned long attrs)
+#endif
 {
+#ifdef HAVE_DMA_MAP_PAGE_ATTRS
 	return dma_map_page_attrs(dev->parent, page, offset, size, dir, attrs);
+#else
+	return dma_map_page(dev->parent, page, offset, size, dir);
+#endif
 }
 
 static void
 mlx5_meddev_dma_unmap_page(struct device *dev, dma_addr_t dma_handle,
 			   size_t size, enum dma_data_direction dir,
+#ifdef HAVE_STRUCT_DMA_ATTRS
+			   struct dma_attrs *attrs)
+#else
 			   unsigned long attrs)
+#endif
 {
+#ifdef HAVE_DMA_MAP_PAGE_ATTRS
 	dma_unmap_page_attrs(dev->parent, dma_handle, size, dir, attrs);
+#else
+	dma_unmap_page(dev->parent, dma_handle, size, dir);
+#endif
 }
 
 static int
 mlx5_meddev_dma_map_sg(struct device *dev, struct scatterlist *sg,
 		       int nents, enum dma_data_direction dir,
+#ifdef HAVE_STRUCT_DMA_ATTRS
+		       struct dma_attrs *attrs)
+#else
 		       unsigned long attrs)
+#endif
 {
 	return dma_map_sg_attrs(dev->parent, sg, nents, dir, attrs);
 }
 
 static void
 mlx5_meddev_dma_unmap_sg(struct device *dev, struct scatterlist *sg, int nents,
+#ifdef HAVE_STRUCT_DMA_ATTRS
+			 enum dma_data_direction dir, struct dma_attrs *attrs)
+#else
 			 enum dma_data_direction dir, unsigned long attrs)
+#endif
 {
 	dma_unmap_sg_attrs(dev->parent, sg, nents, dir, attrs);
 }
 
+#ifdef HAVE_DMA_MAP_OPS_MAP_RESOURCE
 static dma_addr_t
 mlx5_meddev_dma_map_resource(struct device *dev, phys_addr_t phys_addr,
 			     size_t size, enum dma_data_direction dir,
+#ifdef HAVE_STRUCT_DMA_ATTRS
+			     struct dma_attrs *attrs)
+#else
 			     unsigned long attrs)
+#endif
 {
 	return dma_map_resource(dev->parent, phys_addr, size, dir, attrs);
 }
@@ -279,10 +324,15 @@ mlx5_meddev_dma_map_resource(struct devi
 static void
 mlx5_meddev_dma_unmap_resource(struct device *dev, dma_addr_t dma_handle,
 			       size_t size, enum dma_data_direction dir,
+#ifdef HAVE_STRUCT_DMA_ATTRS
+			       struct dma_attrs *attrs)
+#else
 			       unsigned long attrs)
+#endif
 {
 	dma_unmap_resource(dev->parent, dma_handle, size, dir, attrs);
 }
+#endif
 
 static void
 mlx5_meddev_dma_sync_single_for_cpu(struct device *dev,
@@ -316,14 +366,20 @@ mlx5_meddev_dma_sync_sg_for_device(struc
 	dma_sync_sg_for_device(dev->parent, sg, nents, dir);
 }
 
+#ifdef HAVE_DMA_MAP_OPS_CACHE_SYNC
 static void
 mlx5_meddev_dma_cache_sync(struct device *dev, void *vaddr, size_t size,
 			   enum dma_data_direction dir)
 {
 	dma_cache_sync(dev->parent, vaddr, size, dir);
 }
+#endif
 
+#ifdef HAVE_DEVICE_DMA_OPS
 static const struct dma_map_ops mlx5_meddev_dma_ops = {
+#else
+static struct dma_map_ops mlx5_meddev_dma_ops = {
+#endif
 	.alloc = mlx5_meddev_dma_alloc,
 	.free = mlx5_meddev_dma_free,
 	.mmap = mlx5_meddev_dma_mmap,
@@ -332,20 +388,32 @@ static const struct dma_map_ops mlx5_med
 	.unmap_page = mlx5_meddev_dma_unmap_page,
 	.map_sg = mlx5_meddev_dma_map_sg,
 	.unmap_sg = mlx5_meddev_dma_unmap_sg,
+#ifdef HAVE_DMA_MAP_OPS_MAP_RESOURCE
 	.map_resource = mlx5_meddev_dma_map_resource,
 	.unmap_resource = mlx5_meddev_dma_unmap_resource,
+#endif
 	.sync_single_for_cpu = mlx5_meddev_dma_sync_single_for_cpu,
 	.sync_sg_for_cpu = mlx5_meddev_dma_sync_sg_for_cpu,
 	.sync_sg_for_device = mlx5_meddev_dma_sync_sg_for_device,
 	.sync_single_for_device = mlx5_meddev_dma_sync_single_for_device,
+#ifdef HAVE_DMA_MAP_OPS_CACHE_SYNC
 	.cache_sync = mlx5_meddev_dma_cache_sync,
+#endif
 };
 
 static void set_dma_params(struct mlx5_core_dev *coredev, struct device *dev)
 {
 	struct pci_dev *pdev = coredev->pdev;
 
+#ifdef HAVE_DEVICE_DMA_OPS
 	dev->dma_ops = &mlx5_meddev_dma_ops;
+#else
+#ifdef HAVE_SET_DMA_OPS
+	set_dma_ops(dev, &mlx5_meddev_dma_ops);
+#else
+	dev->archdata.dma_ops = &mlx5_meddev_dma_ops;
+#endif
+#endif
 	dev->dma_mask = pdev->dev.dma_mask;
 	dev->dma_parms = pdev->dev.dma_parms;
 	dma_set_coherent_mask(dev, pdev->dev.coherent_dma_mask);
