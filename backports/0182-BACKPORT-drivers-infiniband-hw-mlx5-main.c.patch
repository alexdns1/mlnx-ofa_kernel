From: Valentine Fatiev <valentinef@mellanox.com>
Subject: [PATCH] BACKPORT: drivers/infiniband/hw/mlx5/main.c

Change-Id: I80381bf26b9e180fe3ef372bd9e6b1a01f9c9287
---
 drivers/infiniband/hw/mlx5/main.c | 46 +++++++++++++++++++++++--------
 1 file changed, 34 insertions(+), 12 deletions(-)

--- a/drivers/infiniband/hw/mlx5/main.c
+++ b/drivers/infiniband/hw/mlx5/main.c
@@ -51,7 +51,9 @@
 MODULE_AUTHOR("Eli Cohen <eli@mellanox.com>");
 MODULE_DESCRIPTION("Mellanox 5th generation network adapters (ConnectX series) IB driver");
 MODULE_LICENSE("Dual BSD/GPL");
-
+#ifdef RETPOLINE_MLNX
+MODULE_INFO(retpoline, "Y");
+#endif
 struct mlx5_ib_event_work {
 	struct work_struct	work;
 	union {
@@ -2021,6 +2023,11 @@ static void mlx5_ib_dealloc_ucontext(str
 	struct mlx5_ib_ucontext *context = to_mucontext(ibcontext);
 	struct mlx5_ib_dev *dev = to_mdev(ibcontext->device);
 	struct mlx5_bfreg_info *bfregi;
+#ifndef HAVE_MMU_NOTIFIER_OPS_HAS_FREE_NOTIFIER
+	mutex_lock(&ibcontext->per_mm_list_lock);
+	WARN_ON(!list_empty(&ibcontext->per_mm_list));
+	mutex_unlock(&ibcontext->per_mm_list_lock);
+#endif
 
 	bfregi = &context->bfregi;
 	mlx5_ib_dealloc_transport_domain(dev, context->tdn, context->devx_uid);
@@ -2076,9 +2083,11 @@ static int get_extended_index(unsigned l
 }
 
 
+#if defined(HAVE_PUT_TASK_STRUCT_EXPORTED) && defined (HAVE_GET_TASK_PID_EXPORTED) && defined(HAVE_GET_PID_TASK_EXPORTED)
 static void mlx5_ib_disassociate_ucontext(struct ib_ucontext *ibcontext)
 {
 }
+#endif
 
 static inline char *mmap_cmd2str(enum mlx5_ib_mmap_cmd cmd)
 {
@@ -2186,6 +2195,7 @@ static int uar_mmap(struct mlx5_ib_dev *
 	case MLX5_IB_MMAP_REGULAR_PAGE:
 		/* For MLX5_IB_MMAP_REGULAR_PAGE do the best effort to get WC */
 		prot = pgprot_writecombine(vma->vm_page_prot);
+#if defined(MIDR_CPU_MODEL_MASK)
 #if defined(CONFIG_ARM64)
 		/*
 		 * Fix up arm64 braindamage of using NORMAL_NC for write
@@ -2198,6 +2208,7 @@ static int uar_mmap(struct mlx5_ib_dev *
 			prot = __pgprot_modify(prot, PTE_ATTRINDX_MASK, PTE_ATTRINDX(MT_DEVICE_GRE) | PTE_PXN | PTE_UXN);
 		}
 #endif
+#endif /*MIDR_CPU_MODEL_MASK*/
 		break;
 	case MLX5_IB_MMAP_NC_PAGE:
 		prot = pgprot_noncached(vma->vm_page_prot);
@@ -2347,6 +2358,7 @@ static int mlx5_ib_mmap(struct ib_uconte
 		if (!dev->wc_support)
 			return -EPERM;
 		fallthrough;
+
 	case MLX5_IB_MMAP_NC_PAGE:
 	case MLX5_IB_MMAP_REGULAR_PAGE:
 		return uar_mmap(dev, command, vma, context);
@@ -3385,6 +3397,7 @@ static void mlx5_eth_lag_cleanup(struct
 	}
 }
 
+#ifdef HAVE_UNREGISTER_NETDEVICE_NOTIFIER_NET
 static bool is_ecpf(const struct mlx5_core_dev *dev)
 {
 	/* Check bit-23 to qualify as ECPF taken from ecpf.h */
@@ -3411,16 +3424,19 @@ static bool is_per_net_notifier_dev(cons
 
 	return true;
 }
+#endif
 
 static int mlx5_add_netdev_notifier(struct mlx5_ib_dev *dev, u8 port_num)
 {
 	int err;
 
 	dev->port[port_num].roce.nb.notifier_call = mlx5_netdev_event;
+#ifdef HAVE_UNREGISTER_NETDEVICE_NOTIFIER_NET
 	if (is_per_net_notifier_dev(dev))
 		err = register_netdevice_notifier_net(mlx5_core_net(dev->mdev),
 						      &dev->port[port_num].roce.nb);
 	else
+#endif
 		err = register_netdevice_notifier(&dev->port[port_num].roce.nb);
 	if (err) {
 		dev->port[port_num].roce.nb.notifier_call = NULL;
@@ -3433,10 +3449,12 @@ static int mlx5_add_netdev_notifier(stru
 static void mlx5_remove_netdev_notifier(struct mlx5_ib_dev *dev, u8 port_num)
 {
 	if (dev->port[port_num].roce.nb.notifier_call) {
+#ifdef HAVE_UNREGISTER_NETDEVICE_NOTIFIER_NET
 		if (is_per_net_notifier_dev(dev))
 			unregister_netdevice_notifier_net(mlx5_core_net(dev->mdev),
 							  &dev->port[port_num].roce.nb);
 		else
+#endif
 			unregister_netdevice_notifier(&dev->port[port_num].roce.nb);
 		dev->port[port_num].roce.nb.notifier_call = NULL;
 	}
@@ -4043,9 +4061,10 @@ static const struct uapi_definition mlx5
 static void mlx5_ib_stage_init_cleanup(struct mlx5_ib_dev *dev)
 {
 	mlx5_ib_cleanup_multiport_master(dev);
-	WARN_ON(!xa_empty(&dev->odp_mkeys));
-	cleanup_srcu_struct(&dev->odp_srcu);
-
+#ifdef CONFIG_INFINIBAND_ON_DEMAND_PAGING
+       WARN_ON(!xa_empty(&dev->odp_mkeys));
+       cleanup_srcu_struct(&dev->odp_srcu);
+#endif
 	WARN_ON(!xa_empty(&dev->sig_mrs));
 	WARN_ON(!bitmap_empty(dev->dm.memic_alloc_pages, MLX5_MAX_MEMIC_PAGES));
 }
@@ -4157,7 +4176,9 @@ static const struct ib_device_ops mlx5_i
 	.destroy_qp = mlx5_ib_destroy_qp,
 	.destroy_srq = mlx5_ib_destroy_srq,
 	.detach_mcast = mlx5_ib_mcg_detach,
-	.disassociate_ucontext = mlx5_ib_disassociate_ucontext,
+#if defined(HAVE_PUT_TASK_STRUCT_EXPORTED) && defined (HAVE_GET_TASK_PID_EXPORTED) && defined(HAVE_GET_PID_TASK_EXPORTED)
+       .disassociate_ucontext = mlx5_ib_disassociate_ucontext,
+#endif
 	.drain_rq = mlx5_ib_drain_rq,
 	.drain_sq = mlx5_ib_drain_sq,
 	.enable_driver = mlx5_ib_enable_driver,
@@ -4214,11 +4235,12 @@ static const struct ib_device_ops mlx5_i
 };
 
 static const struct ib_device_ops mlx5_ib_dev_sriov_ops = {
-	.get_vf_config = mlx5_ib_get_vf_config,
-	.get_vf_guid = mlx5_ib_get_vf_guid,
-	.get_vf_stats = mlx5_ib_get_vf_stats,
-	.set_vf_guid = mlx5_ib_set_vf_guid,
-	.set_vf_link_state = mlx5_ib_set_vf_link_state,
+       .get_vf_config = mlx5_ib_get_vf_config,
+       .set_vf_link_state = mlx5_ib_set_vf_link_state,
+       .get_vf_stats = mlx5_ib_get_vf_stats,
+#ifdef HAVE_IFLA_VF_IB_NODE_PORT_GUID
+       .set_vf_guid = mlx5_ib_set_vf_guid,
+#endif
 };
 
 static const struct ib_device_ops mlx5_ib_dev_mw_ops = {
@@ -4323,8 +4345,8 @@ static int mlx5_ib_stage_caps_init(struc
 			ib_set_device_ops(&dev->ib_dev, &mlx5_ib_dev_frontend_ns_context_ops);
 	}
 
-	if (mlx5_core_is_pf(mdev))
-		ib_set_device_ops(&dev->ib_dev, &mlx5_ib_dev_sriov_ops);
+       	if (mlx5_core_is_pf(mdev))
+       		ib_set_device_ops(&dev->ib_dev, &mlx5_ib_dev_sriov_ops);
 
 	dev->umr_fence = mlx5_get_umr_fence(MLX5_CAP_GEN(mdev, umr_fence));
 
