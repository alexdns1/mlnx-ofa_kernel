From: Valentine Fatiev <valentinef@nvidia.com>
Subject: [PATCH] BACKPORT:
 drivers/net/ethernet/mellanox/mlx5/core/en_accel/ipsec_rxtx.h

Change-Id: If48af212fbcf74108077f27a3b3832e306f8860c
---
 .../mellanox/mlx5/core/en_accel/ipsec_rxtx.h    | 17 ++++++++++++++---
 1 file changed, 14 insertions(+), 3 deletions(-)

--- a/drivers/net/ethernet/mellanox/mlx5/core/en_accel/ipsec_rxtx.h
+++ b/drivers/net/ethernet/mellanox/mlx5/core/en_accel/ipsec_rxtx.h
@@ -49,6 +49,9 @@ struct mlx5e_accel_tx_ipsec_state {
 	struct xfrm_state *x;
 	u32 tailen;
 	u32 plen;
+#ifndef HAVE_XFRM_OFFLOAD_INNER_IPPROTO
+	u8 inner_ipproto;
+#endif
 };
 
 #ifdef CONFIG_MLX5_EN_IPSEC
@@ -86,6 +89,9 @@ static inline bool mlx5e_ipsec_is_tx_flo
 }
 
 void mlx5e_ipsec_tx_build_eseg(struct mlx5e_priv *priv, struct sk_buff *skb,
+#ifndef HAVE_XFRM_OFFLOAD_INNER_IPPROTO
+			       struct mlx5e_accel_tx_ipsec_state *ipsec_st,
+#endif
 			       struct mlx5_wqe_eth_seg *eseg);
 
 static inline netdev_features_t
@@ -93,6 +99,11 @@ mlx5e_ipsec_feature_check(struct sk_buff
 {
 	struct xfrm_offload *xo = xfrm_offload(skb);
 	struct sec_path *sp = skb_sec_path(skb);
+#ifdef HAVE_XFRM_OFFLOAD_INNER_IPPROTO
+	u8 inner_ipproto = xo->inner_ipproto;
+#else
+	u8 inner_ipproto = 0;
+#endif
 
 	if (sp && sp->len && xo) {
 		struct xfrm_state *x = sp->xvec[0];
@@ -100,7 +111,7 @@ mlx5e_ipsec_feature_check(struct sk_buff
 		if (!x || !x->xso.offload_handle)
 			goto out_disable;
 
-		if (xo->inner_ipproto) {
+		if (inner_ipproto) {
 			/* Cannot support tunnel packet over IPsec tunnel mode
 			 * because we cannot offload three IP header csum
 			 */
@@ -108,8 +119,8 @@ mlx5e_ipsec_feature_check(struct sk_buff
 				goto out_disable;
 
 			/* Only support UDP or TCP L4 checksum */
-			if (xo->inner_ipproto != IPPROTO_UDP &&
-			    xo->inner_ipproto != IPPROTO_TCP)
+			if (inner_ipproto != IPPROTO_UDP &&
+			    inner_ipproto != IPPROTO_TCP)
 				goto out_disable;
 		}
 
