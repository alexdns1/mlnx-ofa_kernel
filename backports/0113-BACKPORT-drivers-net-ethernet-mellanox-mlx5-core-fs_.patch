From: Mohammad Kabat <mohammadkab@mellanox.com>
Subject: [PATCH] BACKPORT: drivers/net/ethernet/mellanox/mlx5/core/fs_core.c

Change-Id: I4e03a32dda920fbf797949326acfa7e1dc732a19
---
 .../net/ethernet/mellanox/mlx5/core/fs_core.c | 95 +++++++++++++++----
 1 file changed, 75 insertions(+), 20 deletions(-)

--- a/drivers/net/ethernet/mellanox/mlx5/core/fs_core.c
+++ b/drivers/net/ethernet/mellanox/mlx5/core/fs_core.c
@@ -245,15 +245,27 @@ enum fs_i_lock_class {
 };
 
 static const struct rhashtable_params rhash_fte = {
-	.key_len = sizeof_field(struct fs_fte, val),
+#ifndef FIELD_SIZEOF
+        .key_len = sizeof_field(struct fs_fte, val),
+#else
+        .key_len = FIELD_SIZEOF(struct fs_fte, val),
+#endif
 	.key_offset = offsetof(struct fs_fte, val),
 	.head_offset = offsetof(struct fs_fte, hash),
 	.automatic_shrinking = true,
 	.min_size = 1,
 };
 
+#if !defined(HAVE_RHLTABLE) && defined(HAVE_NETNS_FRAGS_RHASHTABLE)
+static const struct bp_rhashtable_params rhash_fg = {
+#else
 static const struct rhashtable_params rhash_fg = {
-	.key_len = sizeof_field(struct mlx5_flow_group, mask),
+#endif
+#ifndef FIELD_SIZEOF
+        .key_len = sizeof_field(struct mlx5_flow_group, mask),
+#else
+        .key_len = FIELD_SIZEOF(struct mlx5_flow_group, mask),
+#endif
 	.key_offset = offsetof(struct mlx5_flow_group, mask),
 	.head_offset = offsetof(struct mlx5_flow_group, hash),
 	.automatic_shrinking = true,
@@ -467,7 +479,9 @@ static void del_hw_flow_table(struct fs_
 	fs_get_obj(ft, node);
 	dev = get_dev(&ft->node);
 	root = find_root(&ft->node);
+#ifndef MLX_DISABLE_TRACEPOINTS
 	trace_mlx5_fs_del_ft(ft);
+#endif
 
 	if (node->active) {
 		err = root->cmds->destroy_flow_table(root, ft);
@@ -483,7 +497,11 @@ static void del_sw_flow_table(struct fs_
 
 	fs_get_obj(ft, node);
 
+#if !defined(HAVE_RHLTABLE) && defined(HAVE_NETNS_FRAGS_RHASHTABLE)
+	bp_rhltable_destroy(&ft->fgs_hash);
+#else
 	rhltable_destroy(&ft->fgs_hash);
+#endif
 	if (ft->node.parent) {
 		fs_get_obj(prio, ft->node.parent);
 		prio->num_ft--;
@@ -519,7 +537,9 @@ static void del_sw_hw_rule(struct fs_nod
 
 	fs_get_obj(rule, node);
 	fs_get_obj(fte, rule->node.parent);
+#ifndef MLX_DISABLE_TRACEPOINTS
 	trace_mlx5_fs_del_rule(rule);
+#endif
 	if (is_fwd_next_action(rule->sw_action)) {
 		mutex_lock(&rule->dest_attr.ft->lock);
 		list_del(&rule->next_ft);
@@ -564,7 +584,9 @@ static void del_hw_fte(struct fs_node *n
 	fs_get_obj(fg, fte->node.parent);
 	fs_get_obj(ft, fg->node.parent);
 
+#ifndef MLX_DISABLE_TRACEPOINTS
 	trace_mlx5_fs_del_fte(fte);
+#endif
 	dev = get_dev(&ft->node);
 	root = find_root(&ft->node);
 	if (node->active) {
@@ -605,7 +627,9 @@ static void del_hw_flow_group(struct fs_
 	fs_get_obj(fg, node);
 	fs_get_obj(ft, fg->node.parent);
 	dev = get_dev(&ft->node);
+#ifndef MLX_DISABLE_TRACEPOINTS
 	trace_mlx5_fs_del_fg(fg);
+#endif
 
 	root = find_root(&ft->node);
 	if (fg->node.active && root->cmds->destroy_flow_group(root, ft, fg))
@@ -629,7 +653,11 @@ static void del_sw_flow_group(struct fs_
 	    fg->max_ftes == ft->autogroup.group_size &&
 	    fg->start_index < ft->autogroup.max_fte)
 		ft->autogroup.num_groups--;
+#if !defined(HAVE_RHLTABLE) && defined(HAVE_NETNS_FRAGS_RHASHTABLE)
+	err = bp_rhltable_remove(&ft->fgs_hash,
+#else
 	err = rhltable_remove(&ft->fgs_hash,
+#endif
 			      &fg->hash,
 			      rhash_fg);
 	WARN_ON(err);
@@ -736,7 +764,11 @@ static struct mlx5_flow_group *alloc_ins
 		return fg;
 
 	/* initialize refcnt, add to parent list */
+#if !defined(HAVE_RHLTABLE) && defined(HAVE_NETNS_FRAGS_RHASHTABLE)
+	ret = bp_rhltable_insert(&ft->fgs_hash,
+#else
 	ret = rhltable_insert(&ft->fgs_hash,
+#endif
 			      &fg->hash,
 			      rhash_fg);
 	if (ret) {
@@ -765,7 +797,11 @@ static struct mlx5_flow_table *alloc_flo
 	if (!ft)
 		return ERR_PTR(-ENOMEM);
 
+#if !defined(HAVE_RHLTABLE) && defined(HAVE_NETNS_FRAGS_RHASHTABLE)
+	ret = bp_rhltable_init(&ft->fgs_hash, &rhash_fg);
+#else
 	ret = rhltable_init(&ft->fgs_hash, &rhash_fg);
+#endif
 	if (ret) {
 		kfree(ft);
 		return ERR_PTR(ret);
@@ -1146,7 +1182,9 @@ static struct mlx5_flow_table *__mlx5_cr
 	fs_prio->num_ft++;
 	up_write_ref_node(&fs_prio->node, false);
 	mutex_unlock(&root->chain_lock);
+#ifndef MLX_DISABLE_TRACEPOINTS
 	trace_mlx5_fs_add_ft(ft);
+#endif
 	return ft;
 destroy_ft:
 	root->cmds->destroy_flow_table(root, ft);
@@ -1248,7 +1286,9 @@ struct mlx5_flow_group *mlx5_create_flow
 		tree_put_node(&fg->node, false);
 		return ERR_PTR(err);
 	}
-	trace_mlx5_fs_add_fg(fg);
+#ifndef MLX_DISABLE_TRACEPOINTS
+       trace_mlx5_fs_add_fg(fg);
+#endif
 	fg->node.active = true;
 
 	return fg;
@@ -1484,7 +1524,9 @@ static int create_auto_flow_group(struct
 	err = root->cmds->create_flow_group(root, ft, in, fg);
 	if (!err) {
 		fg->node.active = true;
+#ifndef MLX_DISABLE_TRACEPOINTS
 		trace_mlx5_fs_add_fg(fg);
+#endif
 	}
 
 	kvfree(in);
@@ -1595,12 +1637,16 @@ static struct mlx5_flow_handle *add_rule
 		fte->action.action = old_action;
 		return handle;
 	}
+#ifndef MLX_DISABLE_TRACEPOINTS
 	trace_mlx5_fs_set_fte(fte, false);
+#endif
 
 	for (i = 0; i < handle->num_rules; i++) {
 		if (refcount_read(&handle->rule[i]->node.refcount) == 1) {
 			tree_add_node(&handle->rule[i]->node, &fte->node);
+#ifndef MLX_DISABLE_TRACEPOINTS
 			trace_mlx5_fs_add_rule(handle->rule[i]);
+#endif
 		}
 	}
 	return handle;
@@ -1673,16 +1719,26 @@ static int build_match_list(struct match
 			    const struct mlx5_flow_spec *spec,
 			    bool ft_locked)
 {
+#if !defined(HAVE_RHLTABLE) && defined(HAVE_NETNS_FRAGS_RHASHTABLE)
+	struct bp_rhlist_head *tmp, *list;
+#else
 	struct rhlist_head *tmp, *list;
+#endif
 	struct mlx5_flow_group *g;
 	int err = 0;
 
 	rcu_read_lock();
 	INIT_LIST_HEAD(&match_head->list);
 	/* Collect all fgs which has a matching match_criteria */
-	list = rhltable_lookup(&ft->fgs_hash, spec, rhash_fg);
+#if !defined(HAVE_RHLTABLE) && defined(HAVE_NETNS_FRAGS_RHASHTABLE)
+	list = bp_rhltable_lookup(&ft->fgs_hash, spec, rhash_fg);
 	/* RCU is atomic, we can't execute FW commands here */
-	rhl_for_each_entry_rcu(g, tmp, list, hash) {
+	bp_rhl_for_each_entry_rcu(g, tmp, list, hash) {
+#else
+       list = rhltable_lookup(&ft->fgs_hash, spec, rhash_fg);
+       /* RCU is atomic, we can't execute FW commands here */
+       rhl_for_each_entry_rcu(g, tmp, list, hash) {
+#endif
 		struct match_list *curr_match;
 
 		if (likely(list_empty(&match_head->list))) {
@@ -1776,25 +1832,24 @@ try_add_to_existing_fg(struct mlx5_flow_
 	fte = alloc_fte(ft, spec, flow_act);
 	if (IS_ERR(fte))
 		return  ERR_PTR(-ENOMEM);
-
 search_again_locked:
 	version = matched_fgs_get_version(match_head);
 	if (flow_act->flags & FLOW_ACT_NO_APPEND)
 		goto skip_search;
-	/* Try to find a fg that already contains a matching fte */
-	list_for_each_entry(iter, match_head, list) {
-		struct fs_fte *fte_tmp;
-
-		g = iter->g;
-		fte_tmp = lookup_fte_locked(g, spec->match_value, take_write);
-		if (!fte_tmp)
-			continue;
-		rule = add_rule_fg(g, spec, flow_act, dest, dest_num, fte_tmp);
-		up_write_ref_node(&fte_tmp->node, false);
-		tree_put_node(&fte_tmp->node, false);
-		kmem_cache_free(steering->ftes_cache, fte);
-		return rule;
-	}
+       /* Try to find a fg that already contains a matching fte */
+       list_for_each_entry(iter, match_head, list) {
+       	struct fs_fte *fte_tmp;
+
+       	g = iter->g;
+       	fte_tmp = lookup_fte_locked(g, spec->match_value, take_write);
+       	if (!fte_tmp)
+       		continue;
+       	rule = add_rule_fg(g, spec, flow_act, dest, dest_num, fte_tmp);
+       	up_write_ref_node(&fte_tmp->node, false);
+       	tree_put_node(&fte_tmp->node, false);
+       	kmem_cache_free(steering->ftes_cache, fte);
+       	return rule;
+       }
 
 skip_search:
 	/* No group with matching fte found, or we skipped the search.
