From: Shay Drory <shayd@nvidia.com>
Subject: [PATCH] BACKPORT: drivers/net/ethernet/mellanox/mlx5/core/eswitch.c

Change-Id: If8ceed540532722bac8ced6220f4e4ac7e413297
---
 .../net/ethernet/mellanox/mlx5/core/eswitch.c | 104 +++++++++++++++++-
 1 file changed, 103 insertions(+), 1 deletion(-)

--- a/drivers/net/ethernet/mellanox/mlx5/core/eswitch.c
+++ b/drivers/net/ethernet/mellanox/mlx5/core/eswitch.c
@@ -921,6 +921,7 @@ static int mlx5_esw_vport_caps_get(struc
 	if (!MLX5_CAP_GEN_MAX(esw->dev, hca_cap_2))
 		goto out_free;
 
+#ifdef HAVE_DEVLINK_HAS_PORT_FN_ROCE_MIG
 	memset(query_ctx, 0, query_out_sz);
 	err = mlx5_vport_get_other_func_cap(esw->dev, vport->vport, query_ctx,
 					    MLX5_CAP_GENERAL_2);
@@ -932,6 +933,7 @@ static int mlx5_esw_vport_caps_get(struc
 #ifdef CONFIG_MLX5_SF_SFC
 	vport->info.local_esw_enabled = MLX5_GET(cmd_hca_cap_2, hca_caps, local_eswitch);
 #endif
+#endif
 out_free:
 	kfree(query_ctx);
 	return err;
@@ -1029,7 +1031,7 @@ int mlx5_esw_vport_enable(struct mlx5_es
 			  enum mlx5_eswitch_vport_event enabled_events)
 {
 	struct mlx5_vport *vport;
-	int ret;
+	int ret = 0;
 
 	vport = mlx5_eswitch_get_vport(esw, vport_num);
 	if (IS_ERR(vport))
@@ -1437,7 +1439,11 @@ static void mlx5_eswitch_get_devlink_par
 	union devlink_param_value val;
 	int err;
 
+#ifdef HAVE_DEVL_PARAM_DRIVERINIT_VALUE_GET
 	err = devl_param_driverinit_value_get(devlink,
+#else
+	err = devlink_param_driverinit_value_get(devlink,
+#endif
 					      MLX5_DEVLINK_PARAM_ID_ESW_LARGE_GROUP_NUM,
 					      &val);
 	if (!err) {
@@ -1609,19 +1615,30 @@ abort:
  */
 int mlx5_eswitch_enable(struct mlx5_eswitch *esw, int num_vfs)
 {
+#if defined(HAVE_DEVL_PORT_REGISTER) && \
+	!defined(HAVE_DEVL_TRAP_GROUPS_REGISTER)
+	struct devlink *devlink;
+#endif
 	bool toggle_lag;
 	int ret = 0;
 
 	if (!mlx5_esw_allowed(esw))
 		return 0;
 
+#ifdef HAVE_DEVL_TRAP_GROUPS_REGISTER
 	devl_assert_locked(priv_to_devlink(esw->dev));
+#endif
 
 	toggle_lag = !mlx5_sriov_is_enabled(esw->dev) && !is_mdev_switchdev_mode(esw->dev);
 
 	if (toggle_lag)
 		mlx5_lag_disable_change(esw->dev);
 
+#if defined(HAVE_DEVL_PORT_REGISTER) && \
+	!defined(HAVE_DEVL_TRAP_GROUPS_REGISTER)
+	devlink = priv_to_devlink(esw->dev);
+	devl_lock(devlink);
+#endif
 	down_write(&esw->mode_lock);
 	if (!mlx5_esw_is_fdb_created(esw)) {
 		ret = mlx5_eswitch_enable_locked(esw, num_vfs);
@@ -1646,6 +1663,10 @@ int mlx5_eswitch_enable(struct mlx5_eswi
 	}
 
 	up_write(&esw->mode_lock);
+#if defined(HAVE_DEVL_PORT_REGISTER) && \
+	!defined(HAVE_DEVL_TRAP_GROUPS_REGISTER)
+	devl_unlock(devlink);
+#endif
 
 	if (toggle_lag)
 		mlx5_lag_enable_change(esw->dev);
@@ -1656,10 +1677,19 @@ int mlx5_eswitch_enable(struct mlx5_eswi
 /* When disabling sriov, free driver level resources. */
 void mlx5_eswitch_disable_sriov(struct mlx5_eswitch *esw, bool clear_vf)
 {
+#if defined(HAVE_DEVL_PORT_REGISTER) && \
+	!defined(HAVE_DEVL_TRAP_GROUPS_REGISTER)
+	struct devlink *devlink;
+#endif
 	if (!mlx5_esw_allowed(esw))
 		return;
 
+#ifdef HAVE_DEVL_TRAP_GROUPS_REGISTER
 	devl_assert_locked(priv_to_devlink(esw->dev));
+#elif defined(HAVE_DEVL_PORT_REGISTER)
+	devlink = priv_to_devlink(esw->dev);
+	devl_lock(devlink);
+#endif
 	down_write(&esw->mode_lock);
 	/* If driver is unloaded, this function is called twice by remove_one()
 	 * and mlx5_unload(). Prevent the second call.
@@ -1682,9 +1712,17 @@ void mlx5_eswitch_disable_sriov(struct m
 	}
 
 	if (esw->mode == MLX5_ESWITCH_OFFLOADS) {
+#ifdef HAVE_DEVLINK_HAS_RATE_FUNCTIONS
 		struct devlink *devlink = priv_to_devlink(esw->dev);
+#endif
 
+#ifdef HAVE_DEVLINK_HAS_RATE_FUNCTIONS
+#ifdef HAVE_DEVL_PORT_REGISTER
 		devl_rate_nodes_destroy(devlink);
+#else
+ 		devlink_rate_nodes_destroy(devlink);
+#endif
+#endif
 	}
 	/* Destroy legacy fdb when disabling sriov in legacy mode. */
 	if (esw->mode == MLX5_ESWITCH_LEGACY)
@@ -1698,6 +1736,10 @@ void mlx5_eswitch_disable_sriov(struct m
 
 unlock:
 	up_write(&esw->mode_lock);
+#if defined(HAVE_DEVL_PORT_REGISTER) && \
+	!defined(HAVE_DEVL_TRAP_GROUPS_REGISTER)
+	devl_unlock(devlink);
+#endif
 }
 
 /* Free resources for corresponding eswitch mode. It is called by devlink
@@ -1705,7 +1747,9 @@ unlock:
  */
 void mlx5_eswitch_disable_locked(struct mlx5_eswitch *esw)
 {
+#ifdef HAVE_DEVLINK_HAS_RATE_FUNCTIONS
 	struct devlink *devlink = priv_to_devlink(esw->dev);
+#endif
 
 	if (esw->mode == MLX5_ESWITCH_OFFLOADS)
 #if IS_ENABLED(CONFIG_MLXDEVM)
@@ -1732,21 +1776,43 @@ void mlx5_eswitch_disable_locked(struct
 		mlx5_esw_acls_ns_cleanup(esw);
 	}
 
+#ifdef HAVE_DEVLINK_HAS_RATE_FUNCTIONS
 	if (esw->mode == MLX5_ESWITCH_OFFLOADS)
+#ifdef HAVE_DEVL_PORT_REGISTER
 		devl_rate_nodes_destroy(devlink);
+#else
+ 		devlink_rate_nodes_destroy(devlink);
+#endif
+#endif
 }
 
 void mlx5_eswitch_disable(struct mlx5_eswitch *esw)
 {
+#if defined(HAVE_DEVL_PORT_REGISTER) && \
+	!defined(HAVE_DEVL_TRAP_GROUPS_REGISTER)
+	struct devlink *devlink;
+#endif
+
 	if (!mlx5_esw_allowed(esw))
 		return;
 
+#ifdef HAVE_DEVL_TRAP_GROUPS_REGISTER
 	devl_assert_locked(priv_to_devlink(esw->dev));
+#endif
 	mlx5_lag_disable_change(esw->dev);
+#if defined(HAVE_DEVL_PORT_REGISTER) && \
+	!defined(HAVE_DEVL_TRAP_GROUPS_REGISTER)
+	devlink = priv_to_devlink(esw->dev);
+	devl_lock(devlink);
+#endif
 	down_write(&esw->mode_lock);
 	mlx5_eswitch_disable_locked(esw);
 	esw->mode = MLX5_ESWITCH_LEGACY;
 	up_write(&esw->mode_lock);
+#if defined(HAVE_DEVL_PORT_REGISTER) && \
+	!defined(HAVE_DEVL_TRAP_GROUPS_REGISTER)
+	devl_unlock(devlink);
+#endif
 	mlx5_lag_enable_change(esw->dev);
 }
 
@@ -1951,6 +2017,7 @@ bool mlx5_esw_host_functions_enabled(con
 	return !dev->priv.eswitch->esw_funcs.host_funcs_disabled;
 }
 
+#if defined(HAVE_DEVLINK_PARAM) && (defined(HAVE_DEVLINK_PARAMS_PUBLISHED) || defined(HAVE_DEVLINK_REGISTER_GET_1_PARAMS))
 static int mlx5_devlink_esw_multiport_set(struct devlink *devlink, u32 id,
 					  struct devlink_param_gset_ctx *ctx)
 {
@@ -2045,6 +2112,22 @@ static const struct devlink_param mlx5_e
 			     mlx5_devlink_esw_pet_insert_set,
 			     mlx5_devlink_esw_pet_insert_validate),
 };
+#endif
+
+#if defined(HAVE_DEVLINK_PARAM) && (defined(HAVE_DEVLINK_PARAMS_PUBLISHED) || defined(HAVE_DEVLINK_REGISTER_GET_1_PARAMS)) && !defined(HAVE_DEVL_PARAM_DRIVERINIT_VALUE_GET)
+int mlx5_register_eswitch_params(struct mlx5_core_dev *dev)
+{
+
+	return  devlink_params_register(priv_to_devlink(dev), mlx5_eswitch_params,
+					ARRAY_SIZE(mlx5_eswitch_params));
+}
+
+void mlx5_unregister_eswitch_params(struct mlx5_core_dev *dev)
+{
+	devlink_params_unregister(priv_to_devlink(dev), mlx5_eswitch_params,
+				  ARRAY_SIZE(mlx5_eswitch_params));
+}
+#endif
 
 int mlx5_eswitch_init(struct mlx5_core_dev *dev)
 {
@@ -2063,10 +2146,12 @@ int mlx5_eswitch_init(struct mlx5_core_d
 	esw->first_host_vport = mlx5_eswitch_first_host_vport_num(dev);
 	dev->priv.eswitch = esw;
 
+#ifdef HAVE_DEVL_PARAM_DRIVERINIT_VALUE_GET
 	err = devl_params_register(priv_to_devlink(dev), mlx5_eswitch_params,
 				   ARRAY_SIZE(mlx5_eswitch_params));
 	if (err)
 		goto free_esw;
+#endif
 
 	esw->work_queue = create_singlethread_workqueue("mlx5_esw_wq");
 	if (!esw->work_queue) {
@@ -2126,9 +2211,11 @@ reps_err:
 abort:
 	if (esw->work_queue)
 		destroy_workqueue(esw->work_queue);
+#ifdef HAVE_DEVL_PARAM_DRIVERINIT_VALUE_GET
 	devl_params_unregister(priv_to_devlink(dev), mlx5_eswitch_params,
 			       ARRAY_SIZE(mlx5_eswitch_params));
 free_esw:
+#endif /* HAVE_DEVL_PARAM_DRIVERINIT_VALUE_GET */
 	dev->priv.eswitch = NULL;
 	kfree(esw);
 	return err;
@@ -2187,7 +2274,9 @@ void mlx5_eswitch_cleanup(struct mlx5_es
 	esw_info(esw->dev, "cleanup\n");
 
 	debugfs_remove_recursive(esw->dbgfs);
+#ifdef HAVE_DEVL_REGISTER
 	esw->dev->priv.eswitch = NULL;
+#endif
 	destroy_workqueue(esw->work_queue);
 	WARN_ON(refcount_read(&esw->qos.refcnt));
 	mutex_destroy(&esw->state_lock);
@@ -2199,8 +2288,13 @@ void mlx5_eswitch_cleanup(struct mlx5_es
 	mutex_destroy(&esw->offloads.decap_tbl_lock);
 	esw_offloads_cleanup(esw);
 	mlx5_esw_vports_cleanup(esw);
+#ifdef HAVE_DEVL_PARAM_DRIVERINIT_VALUE_GET
 	devl_params_unregister(priv_to_devlink(esw->dev), mlx5_eswitch_params,
 			       ARRAY_SIZE(mlx5_eswitch_params));
+#endif
+#ifndef HAVE_DEVL_REGISTER
+	esw->dev->priv.eswitch = NULL;
+#endif
 	kfree(esw);
 }
 
@@ -2554,9 +2648,13 @@ int mlx5_eswitch_get_vport_config(struct
 	ivi->linkstate = evport->info.link_state;
 	ivi->vlan = evport->info.vlan;
 	ivi->qos = evport->info.qos;
+#ifdef HAVE_VF_VLAN_PROTO
 	ivi->vlan_proto = evport->info.vlan_proto;
+#endif
 	ivi->spoofchk = evport->info.spoofchk;
+#ifdef HAVE_VF_INFO_TRUST
 	ivi->trusted = evport->info.trusted;
+#endif
 	if (evport->qos.enabled) {
 		ivi->min_tx_rate = evport->qos.min_rate;
 		ivi->max_tx_rate = evport->qos.max_rate;
@@ -2618,7 +2716,9 @@ int mlx5_eswitch_get_vport_stats(struct
 	struct mlx5_vport *vport = mlx5_eswitch_get_vport(esw, vport_num);
 	int outlen = MLX5_ST_SZ_BYTES(query_vport_counter_out);
 	u32 in[MLX5_ST_SZ_DW(query_vport_counter_in)] = {};
+#ifdef HAVE_STRUCT_IFLA_VF_STATS_RX_TX_DROPPED
 	struct mlx5_vport_drop_stats stats = {};
+#endif
 	int err = 0;
 	u32 *out;
 
@@ -2678,11 +2778,13 @@ int mlx5_eswitch_get_vport_stats(struct
 	vf_stats->broadcast =
 		MLX5_GET_CTR(out, received_eth_broadcast.packets);
 
+#ifdef HAVE_STRUCT_IFLA_VF_STATS_RX_TX_DROPPED
 	err = mlx5_esw_query_vport_drop_stats(esw->dev, vport, &stats);
 	if (err)
 		goto free_out;
 	vf_stats->rx_dropped = stats.rx_dropped;
 	vf_stats->tx_dropped = stats.tx_dropped;
+#endif
 
 free_out:
 	kvfree(out);
