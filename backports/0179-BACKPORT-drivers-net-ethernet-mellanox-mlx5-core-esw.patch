From: Valentine Fatiev <valentinef@nvidia.com>
Subject: [PATCH] BACKPORT:
 drivers/net/ethernet/mellanox/mlx5/core/eswitch_offloads.c

Change-Id: I412b7e05acc6e83111f801e5673ed9dd9b33f855
---
 .../mellanox/mlx5/core/eswitch_offloads.c     | 325 +++++++++++++++++-
 1 file changed, 312 insertions(+), 13 deletions(-)

--- a/drivers/net/ethernet/mellanox/mlx5/core/eswitch_offloads.c
+++ b/drivers/net/ethernet/mellanox/mlx5/core/eswitch_offloads.c
@@ -2671,11 +2671,13 @@ int esw_offloads_load_rep(struct mlx5_es
 	if (esw->mode != MLX5_ESWITCH_OFFLOADS)
 		return 0;
 
+#ifdef HAVE_DEVLINK_PORT_ATRRS_SET_GET_SUPPORT
 	if (vport_num != MLX5_VPORT_UPLINK) {
 		err = mlx5_esw_offloads_devlink_port_register(esw, vport_num);
 		if (err)
 			return err;
 	}
+#endif
 
 	err = mlx5_esw_offloads_rep_load(esw, vport_num);
 	if (err)
@@ -2683,8 +2685,10 @@ int esw_offloads_load_rep(struct mlx5_es
 	return err;
 
 load_err:
+#ifdef HAVE_DEVLINK_PORT_ATRRS_SET_GET_SUPPORT
 	if (vport_num != MLX5_VPORT_UPLINK)
 		mlx5_esw_offloads_devlink_port_unregister(esw, vport_num);
+#endif
 	return err;
 }
 
@@ -2695,8 +2699,10 @@ void esw_offloads_unload_rep(struct mlx5
 
 	mlx5_esw_offloads_rep_unload(esw, vport_num);
 
+#ifdef HAVE_DEVLINK_PORT_ATRRS_SET_GET_SUPPORT
 	if (vport_num != MLX5_VPORT_UPLINK)
 		mlx5_esw_offloads_devlink_port_unregister(esw, vport_num);
+#endif
 }
 
 static int esw_set_slave_root_fdb(struct mlx5_core_dev *master,
@@ -3130,7 +3136,11 @@ u32 mlx5_esw_match_metadata_alloc(struct
 
 	/* Metadata is 4 bits of PFNUM and 12 bits of unique id */
 	/* Use only non-zero vport_id (2-4095) for all PF's */
+#ifdef HAVE_IDA_ALLOC_RANGE
 	id = ida_alloc_range(&esw->offloads.vport_metadata_ida,
+#else
+	id = ida_simple_get(&esw->offloads.vport_metadata_ida,
+#endif
 			     MLX5_ESW_METADATA_RSVD_UPLINK + 1,
 			     vport_end_ida, GFP_KERNEL);
 	if (id < 0)
@@ -3144,7 +3154,11 @@ void mlx5_esw_match_metadata_free(struct
 	u32 vport_bit_mask = (1 << ESW_VPORT_BITS) - 1;
 
 	/* Metadata contains only 12 bits of actual ida id */
-	ida_free(&esw->offloads.vport_metadata_ida, metadata & vport_bit_mask);
+#ifdef HAVE_IDA_FREE
+       ida_free(&esw->offloads.vport_metadata_ida, metadata & vport_bit_mask);
+#else
+	ida_simple_remove(&esw->offloads.vport_metadata_ida, metadata & vport_bit_mask);
+#endif
 }
 
 static int esw_offloads_vport_metadata_setup(struct mlx5_eswitch *esw,
@@ -3407,7 +3421,9 @@ static void esw_offloads_steering_cleanu
 static void
 esw_vfs_changed_event_handler(struct mlx5_eswitch *esw, const u32 *out)
 {
+#ifdef HAVE_DEVL_PORT_REGISTER
 	struct devlink *devlink;
+#endif
 	bool host_pf_disabled;
 	u16 new_num_vfs;
 
@@ -3419,8 +3435,10 @@ esw_vfs_changed_event_handler(struct mlx
 	if (new_num_vfs == esw->esw_funcs.num_vfs || host_pf_disabled)
 		return;
 
+#ifdef HAVE_DEVL_PORT_REGISTER
 	devlink = priv_to_devlink(esw->dev);
 	devl_lock(devlink);
+#endif
 	/* Number of VFs can only change from "0 to x" or "x to 0". */
 	if (esw->esw_funcs.num_vfs > 0) {
 		mlx5_eswitch_unload_vf_vports(esw, esw->esw_funcs.num_vfs);
@@ -3430,12 +3448,16 @@ esw_vfs_changed_event_handler(struct mlx
 		err = mlx5_eswitch_load_vf_vports(esw, new_num_vfs,
 						  MLX5_VPORT_UC_ADDR_CHANGE);
 		if (err) {
+#ifdef HAVE_DEVL_PORT_REGISTER
 			devl_unlock(devlink);
+#endif
 			return;
 		}
 	}
 	esw->esw_funcs.num_vfs = new_num_vfs;
+#ifdef HAVE_DEVL_PORT_REGISTER
 	devl_unlock(devlink);
+#endif
 }
 
 static void esw_functions_changed_event_handler(struct work_struct *work)
@@ -3707,13 +3729,23 @@ static bool esw_offloads_devlink_ns_eq_n
 	return net_eq(devl_net, netdev_net);
 }
 
+#ifdef HAVE_DEVLINK_ESWITCH_MODE_SET_EXTACK
 int mlx5_devlink_eswitch_mode_set(struct devlink *devlink, u16 mode,
 				  struct netlink_ext_ack *extack)
+#else
+int mlx5_devlink_eswitch_mode_set(struct devlink *devlink, u16 mode)
+#endif
 {
+#ifndef HAVE_DEVLINK_ESWITCH_MODE_SET_EXTACK
+	struct netlink_ext_ack *extack;
+#endif
 	u16 cur_mlx5_mode, mlx5_mode = 0;
 	struct mlx5_eswitch *esw;
 	
 	int err = 0;
+#ifndef HAVE_DEVLINK_ESWITCH_MODE_SET_EXTACK
+	extack = NULL;
+#endif
 
 	esw = mlx5_devlink_eswitch_get(devlink);
 	if (IS_ERR(esw))
@@ -3757,12 +3789,14 @@ int mlx5_devlink_eswitch_mode_set(struct
 
 	mlx5_eswitch_disable_locked(esw);
 	if (mode == DEVLINK_ESWITCH_MODE_SWITCHDEV) {
+#ifdef HAVE_DEVLINK_TRAP_SUPPORT
 		if (mlx5_devlink_trap_get_num_active(esw->dev)) {
 			NL_SET_ERR_MSG_MOD(extack,
 					   "Can't change mode while devlink traps are active");
 			err = -EOPNOTSUPP;
 			goto unlock;
 		}
+#endif
 		err = esw_offloads_start(esw, extack);
 	} else if (mode == DEVLINK_ESWITCH_MODE_LEGACY) {
 		err = esw_offloads_stop(esw, extack);
@@ -3828,14 +3862,23 @@ revert_inline_mode:
 	return err;
 }
 
-int mlx5_devlink_eswitch_inline_mode_set(struct devlink *devlink, u8 mode,
-					 struct netlink_ext_ack *extack)
+int mlx5_devlink_eswitch_inline_mode_set(struct devlink *devlink, u8 mode
+#ifdef HAVE_DEVLINK_ESWITCH_MODE_SET_EXTACK
+				 	, struct netlink_ext_ack *extack
+#endif
+				 	)
 {
+#ifndef HAVE_DEVLINK_ESWITCH_MODE_SET_EXTACK
+	struct netlink_ext_ack *extack;
+#endif
 	struct mlx5_core_dev *dev = devlink_priv(devlink);
 	struct mlx5_eswitch *esw;
 	u8 mlx5_mode;
 	int err;
 
+#ifndef HAVE_DEVLINK_ESWITCH_MODE_SET_EXTACK
+	extack = NULL;
+#endif
 	esw = mlx5_devlink_eswitch_get(devlink);
 	if (IS_ERR(esw))
 		return PTR_ERR(esw);
@@ -3900,13 +3943,26 @@ int mlx5_devlink_eswitch_inline_mode_get
 }
 
 int mlx5_devlink_eswitch_encap_mode_set(struct devlink *devlink,
-					enum devlink_eswitch_encap_mode encap,
-					struct netlink_ext_ack *extack)
+#ifdef HAVE_DEVLINK_HAS_ESWITCH_ENCAP_MODE_SET_GET_WITH_ENUM
+					enum devlink_eswitch_encap_mode encap
+#else
+					u8 encap
+#endif
+#ifdef HAVE_DEVLINK_ESWITCH_MODE_SET_EXTACK
+				 	, struct netlink_ext_ack *extack
+#endif
+				 	)
 {
+#ifndef HAVE_DEVLINK_ESWITCH_MODE_SET_EXTACK
+	struct netlink_ext_ack *extack;
+#endif
 	struct mlx5_core_dev *dev = devlink_priv(devlink);
 	struct mlx5_eswitch *esw;
 	int err = 0;
 
+#ifndef HAVE_DEVLINK_ESWITCH_MODE_SET_EXTACK
+	extack = NULL;
+#endif
 	esw = mlx5_devlink_eswitch_get(devlink);
 	if (IS_ERR(esw))
 		return PTR_ERR(esw);
@@ -3959,7 +4015,11 @@ unlock:
 }
 
 int mlx5_devlink_eswitch_encap_mode_get(struct devlink *devlink,
+#ifdef HAVE_DEVLINK_HAS_ESWITCH_ENCAP_MODE_SET_GET_WITH_ENUM
 					enum devlink_eswitch_encap_mode *encap)
+#else
+					u8 *encap)
+#endif
 {
 	struct mlx5_eswitch *esw;
 
@@ -3991,14 +4051,24 @@ mlx5_eswitch_vport_has_rep(const struct
 }
 
 int mlx5_devlink_eswitch_ipsec_mode_set(struct devlink *devlink,
-					enum devlink_eswitch_ipsec_mode ipsec,
-					struct netlink_ext_ack *extack)
+					enum devlink_eswitch_ipsec_mode ipsec
+#ifdef HAVE_DEVLINK_ESWITCH_MODE_SET_EXTACK
+					, struct netlink_ext_ack *extack
+#endif
+					)
 {
+#ifndef HAVE_DEVLINK_ESWITCH_MODE_SET_EXTACK
+	struct netlink_ext_ack *extack;
+#endif
 	struct mlx5_core_dev *dev = devlink_priv(devlink);
 	struct mlx5_eswitch *esw = dev->priv.eswitch;
 	int err = 0;
 
+#ifndef HAVE_DEVLINK_ESWITCH_MODE_SET_EXTACK
+	extack = NULL;
+#else
 	memset(extack, 0, sizeof(*extack));
+#endif
 
 	esw = mlx5_devlink_eswitch_get(devlink);
 	if (IS_ERR(esw))
@@ -4453,15 +4523,24 @@ is_port_function_supported(struct mlx5_e
 	       mlx5_esw_is_sf_vport(esw, vport_num);
 }
 
-int mlx5_devlink_port_function_hw_addr_get(struct devlink_port *port,
-					   u8 *hw_addr, int *hw_addr_len,
-					   struct netlink_ext_ack *extack)
+#ifdef HAVE_PORT_FUNCTION_HW_ADDR_GET_GET_4_PARAM
+int mlx5_devlink_port_function_hw_addr_get(
+#else
+int mlx5_devlink_port_function_hw_addr_get(struct devlink *devlink,
+#endif
+ 					   struct devlink_port *port,
+ 					   u8 *hw_addr, int *hw_addr_len,
+ 					   struct netlink_ext_ack *extack)
 {
 	struct mlx5_eswitch *esw;
 	struct mlx5_vport *vport;
 	u16 vport_num;
 
+#ifdef HAVE_PORT_FUNCTION_HW_ADDR_GET_GET_4_PARAM
 	esw = mlx5_devlink_eswitch_get(port->devlink);
+#else
+	esw = mlx5_devlink_eswitch_get(devlink);
+#endif
 	if (IS_ERR(esw))
 		return PTR_ERR(esw);
 
@@ -4482,14 +4561,23 @@ int mlx5_devlink_port_function_hw_addr_g
 	return 0;
 }
 
-int mlx5_devlink_port_function_hw_addr_set(struct devlink_port *port,
-					   const u8 *hw_addr, int hw_addr_len,
-					   struct netlink_ext_ack *extack)
+#ifdef HAVE_PORT_FUNCTION_HW_ADDR_GET_GET_4_PARAM
+int mlx5_devlink_port_function_hw_addr_set(
+#else
+int mlx5_devlink_port_function_hw_addr_set(struct devlink *devlink,
+#endif
+ 					   struct devlink_port *port,
+ 					   const u8 *hw_addr, int hw_addr_len,
+ 					   struct netlink_ext_ack *extack)
 {
 	struct mlx5_eswitch *esw;
 	u16 vport_num;
 
+#ifdef HAVE_PORT_FUNCTION_HW_ADDR_GET_GET_4_PARAM
 	esw = mlx5_devlink_eswitch_get(port->devlink);
+#else
+	esw = mlx5_devlink_eswitch_get(devlink);
+#endif
 	if (IS_ERR(esw)) {
 		NL_SET_ERR_MSG_MOD(extack, "Eswitch doesn't support set hw_addr");
 		return PTR_ERR(esw);
@@ -4503,3 +4591,214 @@ int mlx5_devlink_port_function_hw_addr_s
 
 	return mlx5_eswitch_set_vport_mac(esw, vport_num, hw_addr);
 }
+
+#ifdef HAVE_DEVLINK_HAS_PORT_FN_ROCE_MIG // forword port
+static struct mlx5_vport *
+mlx5_devlink_port_fn_get_vport(struct devlink_port *port, struct mlx5_eswitch *esw)
+{
+	u16 vport_num;
+
+	if (!MLX5_CAP_GEN(esw->dev, vhca_resource_manager))
+		return ERR_PTR(-EOPNOTSUPP);
+
+	vport_num = mlx5_esw_devlink_port_index_to_vport_num(port->index);
+	if (!is_port_function_supported(esw, vport_num))
+		return ERR_PTR(-EOPNOTSUPP);
+
+	return mlx5_eswitch_get_vport(esw, vport_num);
+}
+
+int mlx5_devlink_port_fn_migratable_get(struct devlink_port *port, bool *is_enabled,
+					struct netlink_ext_ack *extack)
+{
+	struct mlx5_eswitch *esw;
+	struct mlx5_vport *vport;
+	int err = -EOPNOTSUPP;
+
+	esw = mlx5_devlink_eswitch_get(port->devlink);
+	if (IS_ERR(esw))
+		return PTR_ERR(esw);
+
+	if (!MLX5_CAP_GEN(esw->dev, migration)) {
+		NL_SET_ERR_MSG_MOD(extack, "Device doesn't support migration");
+		return err;
+	}
+
+	vport = mlx5_devlink_port_fn_get_vport(port, esw);
+	if (IS_ERR(vport)) {
+		NL_SET_ERR_MSG_MOD(extack, "Invalid port");
+		return PTR_ERR(vport);
+	}
+
+	mutex_lock(&esw->state_lock);
+	if (vport->enabled) {
+		*is_enabled = vport->info.mig_enabled;
+		err = 0;
+	}
+	mutex_unlock(&esw->state_lock);
+	return err;
+}
+
+int mlx5_devlink_port_fn_migratable_set(struct devlink_port *port, bool enable,
+					struct netlink_ext_ack *extack)
+{
+	int query_out_sz = MLX5_ST_SZ_BYTES(query_hca_cap_out);
+	struct mlx5_eswitch *esw;
+	struct mlx5_vport *vport;
+	void *query_ctx;
+	void *hca_caps;
+	int err = -EOPNOTSUPP;
+
+	esw = mlx5_devlink_eswitch_get(port->devlink);
+	if (IS_ERR(esw))
+		return PTR_ERR(esw);
+
+	if (!MLX5_CAP_GEN(esw->dev, migration)) {
+		NL_SET_ERR_MSG_MOD(extack, "Device doesn't support migration");
+		return err;
+	}
+
+	vport = mlx5_devlink_port_fn_get_vport(port, esw);
+	if (IS_ERR(vport)) {
+		NL_SET_ERR_MSG_MOD(extack, "Invalid port");
+		return PTR_ERR(vport);
+	}
+
+	mutex_lock(&esw->state_lock);
+	if (!vport->enabled) {
+		NL_SET_ERR_MSG_MOD(extack, "Eswitch vport is disabled");
+		goto out;
+	}
+
+	if (vport->info.mig_enabled == enable) {
+		err = 0;
+		goto out;
+	}
+
+	query_ctx = kzalloc(query_out_sz, GFP_KERNEL);
+	if (!query_ctx) {
+		err = -ENOMEM;
+		goto out;
+	}
+
+	err = mlx5_vport_get_other_func_cap(esw->dev, vport->vport, query_ctx,
+					    MLX5_CAP_GENERAL_2);
+	if (err) {
+		NL_SET_ERR_MSG_MOD(extack, "Failed getting HCA caps");
+		goto out_free;
+	}
+
+	hca_caps = MLX5_ADDR_OF(query_hca_cap_out, query_ctx, capability);
+	memcpy(hca_caps, MLX5_ADDR_OF(query_hca_cap_out, query_ctx, capability),
+	       MLX5_UN_SZ_BYTES(hca_cap_union));
+	MLX5_SET(cmd_hca_cap_2, hca_caps, migratable, 1);
+
+	err = mlx5_vport_set_other_func_cap(esw->dev, hca_caps, vport->vport,
+					    MLX5_SET_HCA_CAP_OP_MOD_GENERAL_DEVICE2);
+	if (err) {
+		NL_SET_ERR_MSG_MOD(extack, "Failed setting HCA migratable cap");
+		goto out_free;
+	}
+
+	vport->info.mig_enabled = enable;
+
+out_free:
+	kfree(query_ctx);
+out:
+	mutex_unlock(&esw->state_lock);
+	return err;
+}
+
+int mlx5_devlink_port_fn_roce_get(struct devlink_port *port, bool *is_enabled,
+				  struct netlink_ext_ack *extack)
+{
+	struct mlx5_eswitch *esw;
+	struct mlx5_vport *vport;
+	int err = -EOPNOTSUPP;
+
+	esw = mlx5_devlink_eswitch_get(port->devlink);
+	if (IS_ERR(esw))
+		return PTR_ERR(esw);
+
+	vport = mlx5_devlink_port_fn_get_vport(port, esw);
+	if (IS_ERR(vport)) {
+		NL_SET_ERR_MSG_MOD(extack, "Invalid port");
+		return PTR_ERR(vport);
+	}
+
+	mutex_lock(&esw->state_lock);
+	if (vport->enabled) {
+		*is_enabled = vport->info.roce_enabled;
+		err = 0;
+	}
+	mutex_unlock(&esw->state_lock);
+	return err;
+}
+
+int mlx5_devlink_port_fn_roce_set(struct devlink_port *port, bool enable,
+				  struct netlink_ext_ack *extack)
+{
+	int query_out_sz = MLX5_ST_SZ_BYTES(query_hca_cap_out);
+	struct mlx5_eswitch *esw;
+	struct mlx5_vport *vport;
+	int err = -EOPNOTSUPP;
+	void *query_ctx;
+	void *hca_caps;
+	u16 vport_num;
+
+	esw = mlx5_devlink_eswitch_get(port->devlink);
+	if (IS_ERR(esw))
+		return PTR_ERR(esw);
+
+	vport = mlx5_devlink_port_fn_get_vport(port, esw);
+	if (IS_ERR(vport)) {
+		NL_SET_ERR_MSG_MOD(extack, "Invalid port");
+		return PTR_ERR(vport);
+	}
+	vport_num = vport->vport;
+
+	mutex_lock(&esw->state_lock);
+	if (!vport->enabled) {
+		NL_SET_ERR_MSG_MOD(extack, "Eswitch vport is disabled");
+		goto out;
+	}
+
+	if (vport->info.roce_enabled == enable) {
+		err = 0;
+		goto out;
+	}
+
+	query_ctx = kzalloc(query_out_sz, GFP_KERNEL);
+	if (!query_ctx) {
+		err = -ENOMEM;
+		goto out;
+	}
+
+	err = mlx5_vport_get_other_func_cap(esw->dev, vport_num, query_ctx,
+					    MLX5_CAP_GENERAL);
+	if (err) {
+		NL_SET_ERR_MSG_MOD(extack, "Failed getting HCA caps");
+		goto out_free;
+	}
+
+	hca_caps = MLX5_ADDR_OF(query_hca_cap_out, query_ctx, capability);
+	memcpy(hca_caps, MLX5_ADDR_OF(query_hca_cap_out, query_ctx, capability),
+	       MLX5_UN_SZ_BYTES(hca_cap_union));
+	MLX5_SET(cmd_hca_cap, hca_caps, roce, enable);
+
+	err = mlx5_vport_set_other_func_cap(esw->dev, hca_caps, vport_num,
+					    MLX5_SET_HCA_CAP_OP_MOD_GENERAL_DEVICE);
+	if (err) {
+		NL_SET_ERR_MSG_MOD(extack, "Failed setting HCA roce cap");
+		goto out_free;
+	}
+
+	vport->info.roce_enabled = enable;
+
+out_free:
+	kfree(query_ctx);
+out:
+	mutex_unlock(&esw->state_lock);
+	return err;
+}
+#endif // HAVE_DEVLINK_HAS_PORT_FN_ROCE_MIG
